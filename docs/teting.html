<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Advanced example</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 52px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 57px;
  margin-top: -57px;
}

.section h2 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h3 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h4 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h5 {
  padding-top: 57px;
  margin-top: -57px;
}
.section h6 {
  padding-top: 57px;
  margin-top: -57px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MLM-workshop</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Basic example</a>
</li>
<li>
  <a href="teting.html">Advanced example</a>
</li>
<li>
  <a href="further.html">Further reading</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Advanced example</h1>

</div>


<p>This example invovles the use of ordinal models to fit Likert scale data, and additionally some of the trickier aspects of choosing a multilevel structure for ones data.</p>
<div id="load-data-and-packages" class="section level1">
<h1>Load data and packages</h1>
<p>The data come from the first study reportd in a <a href="http://ubc-emotionlab.ca/wp-content/files_mf/tracystecklerheltzelinpressjpsp78.pdf">recent paper</a> investigating the role of disgust for moral judgments. Participants were divided into two conditions and either given ginger or placebo to eat. Roughly an hour later participants saw pictures depicting disgusting scenes and rated their disgust (1-7).</p>
<pre class="r"><code>library(brms)
library(bayesplot)
library(kableExtra)
library(brmstools)</code></pre>
<pre class="r"><code>#set up number of cores to use for fitting
n_cores &lt;- parallel::detectCores()-1</code></pre>
<pre class="r"><code>dat &lt;- read.delim(url(&quot;https://raw.githubusercontent.com/philipparnamets/mlm-workshop/master/data/ginger_data.txt&quot;))</code></pre>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##     subject      Condition    last_meal_time    valence   
##  Min.   :100   Min.   :0.00   Min.   : 0     high   :726  
##  1st Qu.:160   1st Qu.:0.00   1st Qu.: 1     medium :726  
##  Median :220   Median :1.00   Median : 3     neutral:968  
##  Mean   :220   Mean   :0.52   Mean   : 4                  
##  3rd Qu.:281   3rd Qu.:1.00   3rd Qu.: 4                  
##  Max.   :341   Max.   :1.00   Max.   :78                  
##                                                           
##                           item         rating 
##  chair.disgust              :242   Min.   :1  
##  disgust.poop.disgust       :242   1st Qu.:1  
##  disgust.rottenmeat.disgust :242   Median :4  
##  disgust.sneeze.disgust     :242   Mean   :4  
##  disgust.snot.disgust       :242   3rd Qu.:7  
##  disgust.toiletstuff.disgust:242   Max.   :7  
##  (Other)                    :968   NA&#39;s   :5</code></pre>
</div>
<div id="data-visualization" class="section level1">
<h1>Data visualization</h1>
<pre class="r"><code>#define a nice bar plot function
plot_prop &lt;- function(dat, header = &quot;main&quot;,
                        y_max = 0.5){
  #bar plot
  par(mar = c(4,5,3,3)+.1)
  plot(NA, main = &quot;&quot;, xlab = &quot;&quot;, ylab =&quot;&quot;,
       ylim = c(0,y_max), xlim = c(0.35,7.65),
       axes = F)
  axis(1, at = 1:7, 
       lwd = 2, cex.axis = 1.1)
  axis(2, las = 2, lwd = 2, cex.axis = 1.1)
  mtext(&quot;rating&quot;, 1, 2.5, font= 2, cex = 1.2)
  mtext(&quot;proportion&quot;, 2, 3.5, font= 2, cex = 1.2)
  mtext(header, 3, 1, font= 2, cex = 1.3)
  grid(col = &quot;darkgrey&quot;)
  
  tab &lt;- with(dat,
       xtabs(~ rating + Condition))
  tab &lt;- prop.table(tab,2)
  
  for(i in 1:nrow(tab)){
    rect(xleft = i-.4,
         ybottom = 0, 
         xright = i,
         ytop = tab[i,1],
         lwd = 2, col = &quot;darkgray&quot;)
    
    rect(xleft = i,
         ybottom = 0, 
         xright = i+.4,
         ytop = tab[i,2],
         lwd = 2, col = &quot;lightgoldenrod&quot;)
  }
  
  legend(x = 2, y = y_max,
         legend = c(&quot;control&quot;, &quot;ginger&quot;),
         fill = c(&quot;darkgray&quot;, &quot;lightgoldenrod&quot;),
         bty = &#39;n&#39;, cex = 1.2)
}</code></pre>
<pre class="r"><code>plot_prop(dat, &quot;all data&quot;)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>#neutral, high, medium items separately
for (cond in unique(dat$valence)){
  d_tmp &lt;- subset(dat, valence == cond)
  plot_prop(dat = d_tmp, header = cond,
            y_max = 1)
}</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-7-1.png" width="672" /><img src="teting_files/figure-html/unnamed-chunk-7-2.png" width="672" /><img src="teting_files/figure-html/unnamed-chunk-7-3.png" width="672" /></p>
<pre class="r"><code>violinCustom &lt;- function (data, xpos, scaling = 1,
                          shade = &quot;gray&quot;, na_rm = T,
                          whisk = .15){
  #library(sm, quietly = T, verbose=F)
  limit &lt;- c(min(data, na.rm = na_rm),max(data, na.rm = na_rm))
  smout &lt;- sm::sm.density(data, display = &quot;none&quot;, xlim = limit)
  
  # draws the poly
  polygon(x = c(smout$estimate*scaling + xpos, xpos - rev(smout$estimate)*scaling) , 
          y = c(smout$eval.points, rev(smout$eval.points)),
          col = shade)
  
  # put a box in it
  half_width &lt;- max(smout$estimate*scaling)/3 # no wider than half maximum
  Q1 &lt;- quantile(data, 0.25, na.rm = na_rm)
  Q3 &lt;- quantile(data, 0.75, na.rm = na_rm)
  Q2 &lt;- median(data, na.rm = na_rm)
  IQR &lt;- Q3-Q1
  upper = Q2 + IQR*1.5
  if (upper &gt; limit[2]) {upper &lt;- limit[2]}
  lower = Q2 - IQR*1.5
  if (lower &lt; limit[1]) {lower &lt;- limit[1]}
  segments(x0 = xpos, x1 = xpos, y0 = lower, y1 = upper, col = &quot;black&quot;, lwd =2)
  segments(x0 = xpos-whisk, x1 = xpos+whisk, y0 = lower, y1 = lower, col = &quot;black&quot;, lwd = 1.5)
  segments(x0 = xpos-whisk, x1 = xpos+whisk, y0 = upper, y1 = upper, col = &quot;black&quot;, lwd = 1.5)
  polygon(x = c(xpos-half_width, xpos+half_width, xpos+half_width, xpos-half_width),
          y = c(Q1,Q1,Q3,Q3), lwd = 2,
          col = rgb(0.9,0.9,0.9, alpha = 0.5))
  points(xpos, Q2, lwd = 3, cex = 1)
  
}

plot_means &lt;- function(dat, header = &quot;main&quot;,
                       viol_scale = 0.35){
  par(mar=c(4,5,3,3)+.1)
  plot(NA, ylab = &quot;&quot;, xlab = &quot;&quot;, main =&quot;&quot;,
       axes = F,
       xlim = c(0.5,2.5), ylim = c(0.5,7))
  axis(1, at = 1:2, labels = c(&quot;control&quot;,&quot;ginger&quot;), 
       lwd = 2, cex.axis = 1.1)
  axis(2, las = 2, lwd = 2, cex.axis = 1.1)
  mtext(&quot;condition&quot;, 1, 2.5, font= 2, cex = 1.2)
  mtext(&quot;average rating&quot;, 2, 3.5, font= 2, cex = 1.2)
  mtext(header, 3, 1, font= 2, cex = 1.3)
  grid(col = &quot;darkgray&quot;)
  
  #aggregate by subject
  agg &lt;- with(dat, aggregate(rating, list(Condition, subject), 
                    function(x) mean(x, na.rm = T)))
  
  cols &lt;- c(&quot;darkgray&quot;, &quot;lightgoldenrod&quot;)
  cols2 &lt;- c(rgb(169, 169, 169, alpha = 100, maxColorValue = 255),
             rgb(238, 221, 130, alpha = 100, maxColorValue = 255))
  for (i in unique(dat$Condition)){
    # get points to plot
    pp &lt;- agg[agg$Group.1==i,]$x
    
    # plot violin
    violinCustom(data = pp, xpos = i+1,
                 shade = cols2[i+1], scaling = viol_scale)
    
    # plot points
    points(pp ~ jitter(rep(i+1,length(pp)),
                       factor = 1, amount = 0.2),
           pch = &quot;.&quot;, cex = 3, col = cols[i+1])
  }
  
}</code></pre>
<pre class="r"><code>#plot means instead
plot_means(dat, &quot;all data&quot;)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>#all conitions
for (cond in unique(dat$valence)){
  d_tmp &lt;- subset(dat, valence == cond)
  plot_means(dat = d_tmp, header = cond)
}</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-10-1.png" width="672" /><img src="teting_files/figure-html/unnamed-chunk-10-2.png" width="672" /><img src="teting_files/figure-html/unnamed-chunk-10-3.png" width="672" /></p>
</div>
<div id="preliminaries-analysis-of-means" class="section level1">
<h1>Preliminaries: Analysis of means</h1>
<p>Since the authors use t-tests and Anovas in their original paper, we use multi-level models to test the hypothesis, ignoring for now the fact that ratings is ordinal.</p>
<div id="reproducing-original-analysis" class="section level2">
<h2>Reproducing original analysis</h2>
<pre class="r"><code>agg &lt;- with(dat, 
            aggregate(rating, list(Condition,valence, subject),mean))
names(agg) &lt;- c(&quot;condition&quot;, &quot;valence&quot;, &quot;subject&quot;, &quot;rating&quot;)</code></pre>
<p><em>Result 1: ginger does not reduce digust for highly rated stimuli</em></p>
<pre class="r"><code>agg_1 &lt;- subset(agg, valence == &quot;high&quot;)
t.test(rating ~ condition, data = agg_1)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  rating by condition
## t = 1, df = 200, p-value = 0.3
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.09  0.29
## sample estimates:
## mean in group 0 mean in group 1 
##             6.6             6.5</code></pre>
<p>R uses a Welch t-test instead of an independent samples, but it matches the reported results.</p>
<p><em>Result 2: ginger reduces digust for medium rated stimuli</em></p>
<pre class="r"><code>agg_1 &lt;- subset(agg, valence == &quot;medium&quot;)
t.test(rating ~ condition, data = agg_1)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  rating by condition
## t = 2, df = 200, p-value = 0.04
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.011 0.586
## sample estimates:
## mean in group 0 mean in group 1 
##             5.4             5.1</code></pre>
<p>This is <em>marginally</em> significant, but <strong>passes</strong> the .05 level and matches the reported results.</p>
<p>To be fair, the authors could have reported a one-sided test since the hypothesis is obviously directional:</p>
<pre class="r"><code>t.test(rating ~ condition, data = agg_1, alternative = &quot;greater&quot;)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  rating by condition
## t = 2, df = 200, p-value = 0.02
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.057   Inf
## sample estimates:
## mean in group 0 mean in group 1 
##             5.4             5.1</code></pre>
</div>
<div id="using-a-multi-level-gaussian-model-instead" class="section level2">
<h2>Using a multi-level Gaussian model instead</h2>
<p>Since the main results/effects are reported for the medium items, let’s focus on that. The point here is to show that the Gaussian model is a bad idea.</p>
<p>We let condition slopes vary both by subject and stimulus item, and set some weakly informative regularizing priors.</p>
<pre class="r"><code>dat$condition_c &lt;- ifelse(dat$Condition==1,0.5,-0.5)</code></pre>
<pre class="r"><code>dat_fit &lt;- subset(dat, valence == &quot;medium&quot;)
dat_fit &lt;- dat_fit[complete.cases(dat_fit),] # get rid of some (1) missing data
dat_fit$item &lt;- factor(dat_fit$item)

pp &lt;- c(set_prior(&quot;normal(0,.5)&quot;, &quot;b&quot;),
        set_prior(&quot;normal(5,5)&quot;, &quot;Intercept&quot;),
        set_prior(&quot;lkj(3)&quot;, &quot;cor&quot;),
        set_prior(&quot;normal(0,1)&quot;, &quot;sd&quot;, group = &quot;item&quot;),
        set_prior(&quot;normal(0,.5)&quot;, &quot;sd&quot;, group = &quot;subject&quot;),
        set_prior(&quot;normal(0,2)&quot;, &quot;sigma&quot;))

ff &lt;- bf(rating ~ 1 + condition_c +
           (1 + condition_c | subject) + 
           (1 + condition_c | item))

fit_med &lt;- brm(formula = ff, data = dat_fit, 
               family = gaussian(), prior = pp,
               sample_prior = T,
               cores = n_cores, chains = 6,
               iter = 2e3, warmup = 1e3,
               control = list(adapt_delta = 0.95))</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## Start sampling</code></pre>
<pre><code>## Warning: There were 1 divergent transitions after warmup. Increasing adapt_delta above 0.95 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>## Warning: Examine the pairs() plot to diagnose sampling problems</code></pre>
<pre class="r"><code>summary(fit_med)</code></pre>
<pre><code>## Warning: There were 1 divergent transitions after warmup. Increasing adapt_delta above 0.95 may help.
## See http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: rating ~ 1 + condition_c + (1 + condition_c | subject) + (1 + condition_c | item) 
##    Data: dat_fit (Number of observations: 725) 
## Samples: 6 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 6000
## 
## Group-Level Effects: 
## ~item (Number of levels: 3) 
##                            Estimate Est.Error l-95% CI u-95% CI Eff.Sample
## sd(Intercept)                  1.00      0.43     0.43     2.04       3664
## sd(condition_c)                0.23      0.25     0.01     0.91       2656
## cor(Intercept,condition_c)     0.04      0.37    -0.68     0.72       6398
##                            Rhat
## sd(Intercept)              1.00
## sd(condition_c)            1.00
## cor(Intercept,condition_c) 1.00
## 
## ~subject (Number of levels: 242) 
##                            Estimate Est.Error l-95% CI u-95% CI Eff.Sample
## sd(Intercept)                  0.77      0.11     0.52     0.94        317
## sd(condition_c)                0.39      0.30     0.02     1.14        250
## cor(Intercept,condition_c)     0.08      0.30    -0.55     0.65       4215
##                            Rhat
## sd(Intercept)              1.01
## sd(condition_c)            1.02
## cor(Intercept,condition_c) 1.00
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept       5.21      0.64     3.88     6.50       2010 1.00
## condition_c    -0.24      0.20    -0.61     0.20       2781 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     1.35      0.04     1.27     1.44       3843 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>post &lt;- posterior_samples(fit_med, &quot;^b&quot;)
color_scheme_set(&quot;red&quot;)
mcmc_areas(post,
           prob = .8,
           prob_outer = .97)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>We can see that the model does not seem to support the conclusion about an effect of ginger on ratings. However, we can question how reasonable it is with this gaussian assumption:</p>
<pre class="r"><code>pp_check(fit_med)</code></pre>
<pre><code>## Using 10 posterior samples for ppc type &#39;dens_overlay&#39; by default.</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>So instead lets fit a model adapted to Likert scale data.</p>
</div>
</div>
<div id="multi-level-ordinal-response-model" class="section level1">
<h1>Multi-level ordinal response model</h1>
<div id="selecting-a-model" class="section level2">
<h2>Selecting a model</h2>
<p><em>brms</em> supports several ordinal and category models. There is a recent <a href="https://osf.io/cu8jv/">tutorial paper</a> available that details this a bit more.</p>
<p>Here we will use a simple model called the cumulative model (or graded response model), assuming that there is a continuous <em>latent</em> variable underlying participants responses. When the value of that underlying crosses certain thresholds this translates to the different ordinal responses observed. The model is cumulative since we can relate the thresholds to a cumulative distribution function, getting the probability of observing a response at least as high as that threshold. For this workshop we assume an underlying normal distributoin, leading to a <em>probit</em> model. Other choices are possible and the linked paper expands on this greatly.</p>
<p>We can illustrate the probit and some hypothetical thresholds:</p>
<pre class="r"><code>plot(NA, xlim=c(-3,3), ylim = c(0,1),
      xlab = &quot;threshold&quot;, ylab = &quot;cumulative probability&quot;,
      main=&quot;&quot;, cex.axis = 1.2, cex.lab = 1.4)
cord.x &lt;- c(-.7,seq(-.7,1,0.01),1)
cord.y &lt;- c(0,pnorm(seq(-.7,1,0.01)),0)
polygon(cord.x,cord.y,col=&#39;steelblue&#39;, border = F)
abline(v=c(-.7,1), col = &quot;darkblue&quot;, lty = 2, lwd=2)
curve(pnorm, from = -3, to = 3, add=T, lwd=3)
text(x = 0, y = 0.2, 
     labels = paste(round(pnorm(1)-pnorm(-.7),2)*100,&quot;%&quot;),
     col = &quot;white&quot;, cex = 1.5)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>When we estimate the model we will get <strong>N-1</strong> intercepts reflecting the thresholds for <strong>N</strong> categories. The thresholds are just deviates from a standard normal (z-scores). So to get the probability of a specific category we subtract the cumulative probability of one threshold from the one preceeding it.</p>
<p>In the model we additionally formulate effects of variables we measured on the underlying latent variable, in forms of a regression equation. In this model it is assumed that that the effect is uniform over categories. Other ordinal models, however, allow for the estimation of category specific effects.</p>
<p>After all that, the actual model formula is very simple:</p>
<pre class="r"><code>dat_fit$Condition_f &lt;- factor(dat_fit$Condition, 
                              labels = c(&quot;control&quot;, &quot;ginger&quot;))

ff &lt;- bf(rating ~ 1 + Condition_f +
           (1 + Condition_f | subject) + 
           (1 + Condition_f | item),
         family = cumulative(&quot;probit&quot;))</code></pre>
</div>
<div id="prior-predictive-checks" class="section level2">
<h2>Prior predictive checks</h2>
<p>When we are fitting something considerably more complicated, it is extra important to check our modeling assumptions and our priors!</p>
<pre class="r"><code>#what are our priors
kable(get_prior(formula = ff,
          data = dat_fit)) %&gt;%
  kable_styling(c(&quot;striped&quot;, &quot;condensed&quot;), full_width = F)</code></pre>
<table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
prior
</th>
<th style="text-align:left;">
class
</th>
<th style="text-align:left;">
coef
</th>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
resp
</th>
<th style="text-align:left;">
dpar
</th>
<th style="text-align:left;">
nlpar
</th>
<th style="text-align:left;">
bound
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:left;">
Condition_fginger
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
lkj(1)
</td>
<td style="text-align:left;">
cor
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
cor
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
item
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
cor
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
subject
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
student_t(3, 0, 10)
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
student_t(3, 0, 10)
</td>
<td style="text-align:left;">
sd
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
sd
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
item
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
sd
</td>
<td style="text-align:left;">
Condition_fginger
</td>
<td style="text-align:left;">
item
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
sd
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
item
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
sd
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
subject
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
sd
</td>
<td style="text-align:left;">
Condition_fginger
</td>
<td style="text-align:left;">
subject
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
sd
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
subject
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
<p>There is some extra machinery to fit the model here, in that we specify a function to set initial values for the sampling process. To see how that connects with the underlying Stan code, see the Appendix.</p>
<pre class="r"><code>pp &lt;- c(set_prior(&quot;normal(0,3)&quot;, class = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.5)&quot;, class = &quot;b&quot;),
        set_prior(&quot;normal(0,1)&quot;, class = &quot;sd&quot;, group = &quot;item&quot;),
        set_prior(&quot;normal(0,1)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;),
        set_prior(&quot;lkj(3)&quot;, class = &quot;cor&quot;))

tmp_dat &lt;- make_standata(ff,
                            data = dat_fit, 
                         prior = pp)

#a function of initial values
initfun &lt;- function() {
  list(
    b = array(rnorm(tmp_dat$K, 0, 0.1), dim = length(tmp_dat$K)),
    temp_Intercept = seq(-2,2,length.out = tmp_dat$ncat-1) + rnorm(tmp_dat$ncat-1,0,0.1),
    sd_1 = runif(tmp_dat$M_1, 0.5, 1),
    z_1 = matrix(rnorm(tmp_dat$M_1*tmp_dat$N_1, 0, 0.01),
                 tmp_dat$M_1, tmp_dat$N_1),
    L_1 = diag(tmp_dat$M_1)
  )
}</code></pre>
<pre class="r"><code>mod_lik_pr &lt;- brm(ff, 
               data = dat_fit, prior = pp,
               chains = 6, cores = n_cores,
               iter = 2e3, warmup = 1e3,
               inits = initfun,
               sample_prior = &quot;only&quot;)</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## recompiling to avoid crashing R session</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="r"><code>marginal_effects(mod_lik_pr, categorical = T)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<pre class="r"><code>pp_check(mod_lik_pr)</code></pre>
<pre><code>## Using 10 posterior samples for ppc type &#39;dens_overlay&#39; by default.</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-23-2.png" width="672" /></p>
<p>Ok so this is not great.</p>
<p>Below is what I ended up with after going back and forth and tweaking a bit.</p>
<pre class="r"><code>pp &lt;- c(set_prior(&quot;normal(0,1)&quot;, class = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.5)&quot;, class = &quot;b&quot;),
        set_prior(&quot;normal(0,1)&quot;, class = &quot;sd&quot;, group = &quot;item&quot;),
        set_prior(&quot;normal(0,1)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;),
        set_prior(&quot;lkj(3)&quot;, class = &quot;cor&quot;))

mod_lik_pr1 &lt;- brm(ff, 
               data = dat_fit, prior = pp,
               chains = 6, cores = n_cores,
               iter = 2e3, warmup = 1e3,
               inits = initfun,
               sample_prior = &quot;only&quot;)</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## recompiling to avoid crashing R session</code></pre>
<pre><code>## Start sampling</code></pre>
<pre><code>## Warning: There were 3 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>## Warning: Examine the pairs() plot to diagnose sampling problems</code></pre>
<pre class="r"><code>marginal_effects(mod_lik_pr1, categorical = T)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r"><code>pp_check(mod_lik_pr1)</code></pre>
<pre><code>## Using 10 posterior samples for ppc type &#39;dens_overlay&#39; by default.</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-24-2.png" width="672" /></p>
<p>That looks reasonable enough.</p>
</div>
<div id="fitting-the-model" class="section level2">
<h2>Fitting the model</h2>
<p>Now we fit the model, with some added control statements to help get rid of the warnings we saw earlier.</p>
<pre class="r"><code>mod_lik &lt;- brm(ff, 
               data = dat_fit, prior = pp,
               chains = 6, cores = n_cores,
               iter = 2e3, warmup = 1e3,
               inits = initfun,
               sample_prior = T,
               control= list(adapt_delta =0.95,
                             max_treedepth = 15))</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## recompiling to avoid crashing R session</code></pre>
<pre><code>## Start sampling</code></pre>
</div>
<div id="diagnostics" class="section level2">
<h2>Diagnostics</h2>
<p>Again we want to run diagnostics on our model to make sure it is sensible.</p>
<pre class="r"><code>all_hats &lt;- rhat(mod_lik)
mcmc_rhat_hist(all_hats)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<pre class="r"><code>neffs &lt;- neff_ratio(mod_lik)
mcmc_neff_hist(neffs, binwidth = 0.05)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r"><code># which parameters have low neff
mcmc_neff(neffs[neffs&lt;0.1]) + yaxis_text(hjust = 1)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>We see that the model is sampling really inefficiently for some parameters. To fix this we need to adjust the priors. Again, here I went back and forth adjusting priors and refitting the model until I was satisfied. The final results is below:</p>
<pre class="r"><code>pp &lt;- c(set_prior(&quot;normal(0,1)&quot;, class = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.5)&quot;, class = &quot;b&quot;),
        set_prior(&quot;normal(0,1)&quot;, class = &quot;sd&quot;, group = &quot;item&quot;),
        set_prior(&quot;normal(0,0.5)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;, coef = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.15)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;, coef = &quot;Condition_fginger&quot;),
        set_prior(&quot;lkj(3)&quot;, class = &quot;cor&quot;))

mod_lik2 &lt;- brm(ff, 
               data = dat_fit, prior = pp,
               chains = 6, cores = n_cores,
               iter = 4e3, warmup = 2e3,
               inits = initfun,
               sample_prior = T,
               control= list(adapt_delta =0.98,
                             max_treedepth = 15))</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## recompiling to avoid crashing R session</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="r"><code>neffs &lt;- neff_ratio(mod_lik2)
mcmc_neff_hist(neffs, binwidth = 0.05)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>And we’re good!</p>
</div>
<div id="posterior-predictive-checks" class="section level2">
<h2>Posterior predictive checks</h2>
<p>OK, let’s evaluate the posterior of the model.</p>
<pre class="r"><code>summary(mod_lik2)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = probit; disc = identity 
## Formula: rating ~ 1 + Condition_f + (1 + Condition_f | subject) + (1 + Condition_f | item) 
##    Data: dat_fit (Number of observations: 725) 
## Samples: 6 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Group-Level Effects: 
## ~item (Number of levels: 3) 
##                                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)                        0.93      0.41     0.38     1.92       5913 1.00
## sd(Condition_fginger)                0.19      0.22     0.01     0.80       6008 1.00
## cor(Intercept,Condition_fginger)     0.01      0.38    -0.70     0.71      16323 1.00
## 
## ~subject (Number of levels: 242) 
##                                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)                        0.68      0.08     0.52     0.83       3998 1.00
## sd(Condition_fginger)                0.12      0.09     0.00     0.34       2366 1.00
## cor(Intercept,Condition_fginger)     0.08      0.36    -0.61     0.72      14830 1.00
## 
## Population-Level Effects: 
##                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]         -1.92      0.36    -2.60    -1.17       5638 1.00
## Intercept[2]         -1.32      0.36    -1.98    -0.58       5583 1.00
## Intercept[3]         -1.01      0.36    -1.66    -0.27       5581 1.00
## Intercept[4]         -0.11      0.36    -0.75     0.63       5592 1.00
## Intercept[5]          0.32      0.36    -0.33     1.06       5558 1.00
## Intercept[6]          1.11      0.36     0.45     1.86       5538 1.00
## Condition_fginger    -0.22      0.17    -0.56     0.12       5717 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>pp_check(mod_lik2)</code></pre>
<pre><code>## Using 10 posterior samples for ppc type &#39;dens_overlay&#39; by default.</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>This looks very good (compare to gaussian model earlier!).</p>
<pre class="r"><code>marginal_effects(mod_lik2, categorical = T)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>On a first pass, this might seem reasonable, there looks like a small difference between categories and they vary in their expected probabilities. However, compare to the actual data:</p>
<pre class="r"><code>plot_prop(dat_fit, &quot;the data&quot;)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>We see that the modal response is 7 and not 4 as in that plot. But we also saw in the first posterior density check that the model seems to be predicting the data. What is going on here?</p>
<p>First we can verify that the model is predicting the data well:</p>
<pre class="r"><code>ypred_sum &lt;- predict(mod_lik2)
str(ypred_sum)</code></pre>
<pre><code>##  num [1:725, 1:7] 0.001417 0.0075 0.007083 0.000667 0.000417 ...
##  - attr(*, &quot;dimnames&quot;)=List of 2
##   ..$ : NULL
##   ..$ : chr [1:7] &quot;P(Y = 1)&quot; &quot;P(Y = 2)&quot; &quot;P(Y = 3)&quot; &quot;P(Y = 4)&quot; ...</code></pre>
<pre class="r"><code>observed &lt;- prop.table(table(dat_fit$rating))
predicted &lt;- colMeans(ypred_sum)
cbind(observed, predicted)</code></pre>
<pre><code>##   observed predicted
## 1    0.039     0.040
## 2    0.058     0.057
## 3    0.047     0.047
## 4    0.207     0.206
## 5    0.121     0.123
## 6    0.228     0.227
## 7    0.301     0.299</code></pre>
<p>The difference, it turns out that the <em>marginal_effects()</em> call uses the population-level estimates <strong>only</strong>, while <em>predict()</em> <strong>also</strong> uses the group-level estimates. Let’s verify this by a quick calculation, and then think about why this matters in this model.</p>
<p><em>NOTE: We are usually much more interested in the predictions coming from the full model, so its in a sense much more important that they have good concordance with the data. Part of this is an excuse to delve deeper into the nitty gritty of evaluating the model.</em></p>
<pre class="r"><code>#extract the population level estimates
estimates &lt;- fixef(mod_lik2)
estimates</code></pre>
<pre><code>##                   Estimate Est.Error  Q2.5 Q97.5
## Intercept[1]         -1.92      0.36 -2.60 -1.17
## Intercept[2]         -1.32      0.36 -1.98 -0.58
## Intercept[3]         -1.01      0.36 -1.66 -0.27
## Intercept[4]         -0.11      0.36 -0.75  0.63
## Intercept[5]          0.32      0.36 -0.33  1.06
## Intercept[6]          1.11      0.36  0.45  1.86
## Condition_fginger    -0.22      0.17 -0.56  0.12</code></pre>
<pre class="r"><code>#keep the intercepts
estimates &lt;- estimates[1:6]

#get cumulative probabilities
prob_est &lt;- pnorm(estimates)

# add 1 for final category
prob_est &lt;- c(prob_est,1)
prob_est</code></pre>
<pre><code>## [1] 0.027 0.093 0.156 0.457 0.624 0.866 1.000</code></pre>
<pre class="r"><code>#probailities of each response [for control condition]
c(prob_est[1], diff(prob_est))</code></pre>
<pre><code>## [1] 0.027 0.066 0.063 0.301 0.167 0.241 0.134</code></pre>
<p>We see that these match the expected values in the left panel of the marginal effects plot.</p>
<p>This is highly unusual. If we review the summary of the model, on thing that stands out is that we only have 3 levels of the item category. Most people doing multi-level modeling will probably tell you that is not ideal (but, importantly, its not a no-no either.</p>
<p>Let’s plot the data for each item separately:</p>
<pre class="r"><code>#items separately
for (it in unique(dat_fit$item)){
  d_tmp &lt;- subset(dat, item == it)
  plot_prop(dat = d_tmp, header = it,
            y_max = 1)
}</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-38-1.png" width="672" /><img src="teting_files/figure-html/unnamed-chunk-38-2.png" width="672" /><img src="teting_files/figure-html/unnamed-chunk-38-3.png" width="672" /></p>
<p>Responses to the items appear to be really different. Let’s look at the fitted coefficients:</p>
<pre class="r"><code>ranef(mod_lik2)$item</code></pre>
<pre><code>## , , Intercept
## 
##                            Estimate Est.Error   Q2.5 Q97.5
## disgust.rottenmeat.disgust    -0.13      0.36 -0.765  0.62
## disgust.sneeze.disgust         0.55      0.36 -0.095  1.31
## disgust.snot.disgust           1.10      0.37  0.446  1.87
## 
## , , Condition_fginger
## 
##                            Estimate Est.Error  Q2.5 Q97.5
## disgust.rottenmeat.disgust   -0.014      0.15 -0.34  0.31
## disgust.sneeze.disgust        0.018      0.15 -0.29  0.36
## disgust.snot.disgust          0.012      0.16 -0.32  0.37</code></pre>
<p>Two things stand out:</p>
<ol style="list-style-type: decimal">
<li>There are <strong>large</strong> differences in the estimated intercept depending on item. (Remember, these are on a standard normal scale)<br />
</li>
<li>There are very <strong>small</strong> differences in the estimated slopes - which is the variable we care about in this analysis.</li>
</ol>
<p>While not conclusive, it is hinting us that maybe we should look into this a bit more.</p>
</div>
<div id="fitting-an-alternative-model" class="section level2">
<h2>Fitting an alternative model</h2>
<p>Here we refit the model but drop the varying effects for items.</p>
<pre class="r"><code>ff &lt;- bf(rating ~ 1 + Condition_f +
           (1 + Condition_f | subject),
         family = cumulative(&quot;probit&quot;))

pp &lt;- c(set_prior(&quot;normal(0,1)&quot;, class = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.5)&quot;, class = &quot;b&quot;),
        set_prior(&quot;normal(0,0.5)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;, coef = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.15)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;, coef = &quot;Condition_fginger&quot;),
        set_prior(&quot;lkj(3)&quot;, class = &quot;cor&quot;))

tmp_dat &lt;- make_standata(ff,
                            data = dat_fit, 
                         prior = pp)

#a function of initial values
initfun &lt;- function() {
  list(
    b = array(rnorm(tmp_dat$K, 0, 0.1), dim = length(tmp_dat$K)),
    temp_Intercept = seq(-2,2,length.out = tmp_dat$ncat-1) + rnorm(tmp_dat$ncat-1,0,0.1),
    sd_1 = runif(tmp_dat$M_1, 0.5, 1),
    z_1 = matrix(rnorm(tmp_dat$M_1*tmp_dat$N_1, 0, 0.01),
                 tmp_dat$M_1, tmp_dat$N_1),
    L_1 = diag(tmp_dat$M_1)
  )
}

mod_lik3 &lt;- brm(ff, 
               data = dat_fit, prior = pp,
               chains = 6, cores = n_cores,
               iter = 4e3, warmup = 2e3,
               inits = initfun,
               sample_prior = T,
               control= list(adapt_delta =0.98,
                             max_treedepth = 15))</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## recompiling to avoid crashing R session</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="r"><code>pp_check(mod_lik4)</code></pre>
<pre><code>## Using 10 posterior samples for ppc type &#39;dens_overlay&#39; by default.</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<pre class="r"><code>marginal_effects(mod_lik3, categorical = T)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<p>The marginal effects now resemble our expectations better.</p>
<pre class="r"><code>summary(mod_lik3)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = probit; disc = identity 
## Formula: rating ~ 1 + Condition_f + (1 + Condition_f | subject) 
##    Data: dat_fit (Number of observations: 725) 
## Samples: 6 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Group-Level Effects: 
## ~subject (Number of levels: 242) 
##                                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)                        0.46      0.08     0.30     0.62       2671 1.00
## sd(Condition_fginger)                0.12      0.09     0.01     0.34       2717 1.00
## cor(Intercept,Condition_fginger)     0.05      0.36    -0.63     0.72      12363 1.00
## 
## Population-Level Effects: 
##                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]         -2.04      0.12    -2.27    -1.82       8760 1.00
## Intercept[2]         -1.53      0.10    -1.72    -1.34      10048 1.00
## Intercept[3]         -1.27      0.09    -1.44    -1.09      10561 1.00
## Intercept[4]         -0.52      0.08    -0.68    -0.37      12054 1.00
## Intercept[5]         -0.17      0.08    -0.32    -0.02      12413 1.00
## Intercept[6]          0.49      0.08     0.34     0.65      11844 1.00
## Condition_fginger    -0.19      0.10    -0.38     0.01      10916 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We can see that the estimated intercepts are very different now as well.</p>
<div id="model-comparison" class="section level3">
<h3>Model comparison</h3>
<p>Which model should we do our inference on. This is tricky and there won’t be just one answer. Here we will rely on model comparison via LOO-CV.</p>
<pre class="r"><code>loo_lik2 &lt;- loo::loo(mod_lik2, cores = 3, reloo = T)
loo_lik3 &lt;- loo::loo(mod_lik3, cores = 3, reloo = T)</code></pre>
<pre class="r"><code>compare_ic(loo_lik2, loo_lik3)</code></pre>
<pre><code>##                     LOOIC SE
## mod_lik2             2292 39
## mod_lik3             2459 36
## mod_lik2 - mod_lik3  -168 23</code></pre>
<p>We see that our original model is preferred after all!</p>
<p>Let’s plot the category-wise predictions together with our data.</p>
<pre class="r"><code>plot_prop(dat_fit, &quot;data + model&quot;)

c_pred &lt;- colMeans(ypred_sum[dat_fit$Condition==0,])
c_quant &lt;- apply(ypred_sum[dat_fit$Condition==0,], 2, function(x) quantile(x, c(.25,.75)))
points(x = seq(1,7)-.2, y= c_pred, 
       pch = &quot;X&quot;, cex = 1.8)
segments(x0 = seq(1,7)-.2, 
         y0 = c_quant[1,],
         y1 = c_quant[2,],
         lwd = 2)

g_pred &lt;- colMeans(ypred_sum[dat_fit$Condition==1,])
g_quant &lt;- apply(ypred_sum[dat_fit$Condition==1,], 2, function(x) quantile(x, c(.25,.75)))
points(x = seq(1,7)+.2, y= g_pred,
       pch = &quot;X&quot;, cex = 1.8, col = &quot;red&quot;)
segments(x0 = seq(1,7)+.2, 
         y0 = g_quant[1,],
         y1 = g_quant[2,],
         lwd = 2, col = &quot;red&quot;)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
</div>
</div>
<div id="inference" class="section level2">
<h2>Inference</h2>
<pre class="r"><code>post &lt;- posterior_samples(mod_lik2, &quot;^b&quot;)
q_97 &lt;- quantile(post$b_Condition_fginger, c(0.015, 0.985))
q_97</code></pre>
<pre><code>##  1.5%   98% 
## -0.63  0.17</code></pre>
<p>We can also calculate the posterior probability that the effect is less than 0:</p>
<pre class="r"><code>prob &lt;- sum(post$b_Condition_fginger&lt;0)/length(post$b_Condition_fginger)
paste(prob*100,&quot;% of samples are less than 0&quot;)</code></pre>
<pre><code>## [1] &quot;91.7416666666667 % of samples are less than 0&quot;</code></pre>
<p>We can straightforwardly combine this information in a plot:</p>
<pre class="r"><code>mcmc_hist(post, &quot;b_Condition_fginger&quot;, binwidth = 0.025) +
  geom_vline(xintercept = 0, size = 1.5, linetype = &quot;dashed&quot;) +
  geom_segment(aes(x = q_97[1], xend = q_97[2], y = 5, yend = 5),
               size = 1.5, colour = &quot;yellow&quot;) +
  annotate(&quot;text&quot;, 
           x = mean(q_97), y = 30,
           label = paste(&quot;97% CI: [&quot;, round(q_97[1],2), &quot;,&quot; , round(q_97[2],2), &quot;]&quot; ),
           colour = &quot;yellow&quot;, fontface = 2) +
  annotate(&quot;text&quot;,
           x = -0.9, y = 300,
           label = paste(prob*100,&quot;% of samples \nare less than 0&quot;),
           fontface = 2)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<p>With this method the answer to our question is maybe!</p>
<p>Let’s also assess with Bayes Factors.</p>
<pre class="r"><code>h &lt;- hypothesis(mod_lik2, &quot;Condition_fginger=0&quot;)
h</code></pre>
<pre><code>## Hypothesis Tests for class b:
##                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star
## 1 (Condition_fginger) = 0    -0.22      0.17    -0.56     0.12        1.1      0.53     
## ---
## &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI.
## Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
<pre class="r"><code>plot(h)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<p>With this method the answer is that it is as likely as it was before (see Appendix A for the effect of changing the prior)</p>
</div>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>We have seen:</p>
<ul>
<li>It is probably a good idea to analyze ordinal data using ordinal models</li>
<li>Finding a good model can take time</li>
<li>Taking the multi-level structure of our data into account, affects what we conclude about the data using the model</li>
</ul>
</div>
<div id="appendix-a-priors-and-bayes-factors" class="section level1">
<h1>Appendix A : Priors and Bayes Factors</h1>
<pre class="r"><code>ff &lt;- bf(rating ~ 1 + Condition_f +
           (1 + Condition_f | subject),
         family = cumulative(&quot;probit&quot;))

pp &lt;- c(set_prior(&quot;normal(0,1)&quot;, class = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.1)&quot;, class = &quot;b&quot;),
        set_prior(&quot;normal(0,0.5)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;, coef = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.15)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;, coef = &quot;Condition_fginger&quot;),
        set_prior(&quot;lkj(3)&quot;, class = &quot;cor&quot;))

tmp_dat &lt;- make_standata(ff,
                            data = dat_fit, 
                         prior = pp)

#a function of initial values
initfun &lt;- function() {
  list(
    b = array(rnorm(tmp_dat$K, 0, 0.1), dim = length(tmp_dat$K)),
    temp_Intercept = seq(-2,2,length.out = tmp_dat$ncat-1) + rnorm(tmp_dat$ncat-1,0,0.1),
    sd_1 = runif(tmp_dat$M_1, 0.5, 1),
    z_1 = matrix(rnorm(tmp_dat$M_1*tmp_dat$N_1, 0, 0.01),
                 tmp_dat$M_1, tmp_dat$N_1),
    L_1 = diag(tmp_dat$M_1)
  )
}

mod_lik4 &lt;- brm(ff, 
               data = dat_fit, prior = pp,
               chains = 6, cores = n_cores,
               iter = 4e3, warmup = 2e3,
               inits = initfun,
               sample_prior = T,
               control= list(adapt_delta =0.98,
                             max_treedepth = 15))</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## recompiling to avoid crashing R session</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="r"><code>post &lt;- posterior_samples(mod_lik4, &quot;^b&quot;)
q_97 &lt;- quantile(post$b_Condition_fginger, c(0.015, 0.985))
q_97</code></pre>
<pre><code>##   1.5%    98% 
## -0.253  0.062</code></pre>
<p>Very similar to before.</p>
<pre class="r"><code>prob &lt;- sum(post$b_Condition_fginger&lt;0)/length(post$b_Condition_fginger)
paste(round(prob,2)*100,&quot;% of samples are less than 0&quot;)</code></pre>
<pre><code>## [1] &quot;91 % of samples are less than 0&quot;</code></pre>
<pre class="r"><code>mcmc_hist(post, &quot;b_Condition_fginger&quot;, binwidth = 0.025) +
  geom_vline(xintercept = 0, size = 1.5, linetype = &quot;dashed&quot;) +
  geom_segment(aes(x = q_97[1], xend = q_97[2], y = 5, yend = 5),
               size = 1.5, colour = &quot;yellow&quot;) +
  annotate(&quot;text&quot;, 
           x = mean(q_97), y = 30,
           label = paste(&quot;97% CI: [&quot;, round(q_97[1],2), &quot;,&quot; , round(q_97[2],2), &quot;]&quot; ),
           colour = &quot;yellow&quot;, fontface = 2) +
  annotate(&quot;text&quot;,
           x = -0.9, y = 300,
           label = paste(prob*100,&quot;% of samples \nare less than 0&quot;),
           fontface = 2)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>With this method the answer doesn’t change much.</p>
<p>Let’s also assess with Bayes Factors.</p>
<pre class="r"><code>h &lt;- hypothesis(mod_lik4, &quot;Condition_fginger=0&quot;)
h</code></pre>
<pre><code>## Hypothesis Tests for class b:
##                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star
## 1 (Condition_fginger) = 0     -0.1      0.07    -0.23     0.05       0.58      0.37     
## ---
## &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI.
## Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
<pre class="r"><code>plot(h)</code></pre>
<p><img src="teting_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<p>With this method the answer BF is suddenly close to 2. Not super-strong evidence, but a different story than earlier.</p>
</div>
<div id="appendix-b-viewing-stan-code" class="section level1">
<h1>Appendix B : Viewing Stan code</h1>
<p>Viewing Stan code.</p>
<pre class="r"><code>ff &lt;- bf(rating ~ 1 + Condition_f +
           (1 + Condition_f | subject) + 
           (1 + Condition_f | item),
         family = cumulative(&quot;probit&quot;))

pp &lt;- c(set_prior(&quot;normal(0,3)&quot;, class = &quot;Intercept&quot;),
        set_prior(&quot;normal(0,0.5)&quot;, class = &quot;b&quot;),
        set_prior(&quot;normal(0,1)&quot;, class = &quot;sd&quot;, group = &quot;item&quot;),
        set_prior(&quot;normal(0,1)&quot;, class = &quot;sd&quot;, group = &quot;subject&quot;),
        set_prior(&quot;lkj(3)&quot;, class = &quot;cor&quot;))

make_stancode(ff,data = dat_fit, prior = pp)</code></pre>
<pre><code>## // generated with brms 2.6.0
## functions { 
##   /* cumulative-probit log-PDF for a single response
##    * Args:
##    *   y: response category
##    *   mu: linear predictor
##    *   thres: ordinal thresholds
##    *   disc: discrimination parameter
##    * Returns:
##    *   a scalar to be added to the log posterior
##    */
##    real cumulative_probit_lpmf(int y, real mu, vector thres, real disc) {
##      int ncat = num_elements(thres) + 1;
##      real p;
##      if (y == 1) {
##        p = Phi(disc * (thres[1] - mu));
##      } else if (y == ncat) {
##        p = 1 - Phi(disc * (thres[ncat - 1] - mu));
##      } else {
##        p = Phi(disc * (thres[y] - mu)) -
##            Phi(disc * (thres[y - 1] - mu));
##      }
##      return log(p);
##    } 
##   /* cumulative-probit log-PDF for a single response
##    * including category specific effects
##    * Args:
##    *   y: response category
##    *   mu: linear predictor
##    *   mucs: predictor for category specific effects
##    *   thres: ordinal thresholds
##    *   disc: discrimination parameter
##    * Returns:
##    *   a scalar to be added to the log posterior
##    */
##    real cumulative_probit_cs_lpmf(int y, real mu, row_vector mucs, vector thres, real disc) {
##      int ncat = num_elements(thres) + 1;
##      real p;
##      if (y == 1) {
##        p = Phi(disc * (thres[1] - mucs[1] - mu));
##      } else if (y == ncat) {
##        p = 1 - Phi(disc * (thres[ncat - 1] - mucs[ncat - 1] - mu));
##      } else {
##        p = Phi(disc * (thres[y] - mucs[y] - mu)) -
##            Phi(disc * (thres[y - 1] - mucs[y - 1] - mu));
##      }
##      return log(p);
##    } 
## } 
## data { 
##   int&lt;lower=1&gt; N;  // total number of observations 
##   int Y[N];  // response variable 
##   int&lt;lower=2&gt; ncat;  // number of categories 
##   int&lt;lower=1&gt; K;  // number of population-level effects 
##   matrix[N, K] X;  // population-level design matrix 
##   real&lt;lower=0&gt; disc;  // discrimination parameters 
##   // data for group-level effects of ID 1
##   int&lt;lower=1&gt; J_1[N];
##   int&lt;lower=1&gt; N_1;
##   int&lt;lower=1&gt; M_1;
##   vector[N] Z_1_1;
##   vector[N] Z_1_2;
##   int&lt;lower=1&gt; NC_1;
##   // data for group-level effects of ID 2
##   int&lt;lower=1&gt; J_2[N];
##   int&lt;lower=1&gt; N_2;
##   int&lt;lower=1&gt; M_2;
##   vector[N] Z_2_1;
##   vector[N] Z_2_2;
##   int&lt;lower=1&gt; NC_2;
##   int prior_only;  // should the likelihood be ignored? 
## } 
## transformed data { 
##   int Kc = K - 1; 
##   matrix[N, K - 1] Xc;  // centered version of X 
##   vector[K - 1] means_X;  // column means of X before centering 
##   for (i in 2:K) { 
##     means_X[i - 1] = mean(X[, i]); 
##     Xc[, i - 1] = X[, i] - means_X[i - 1]; 
##   } 
## } 
## parameters { 
##   vector[Kc] b;  // population-level effects 
##   ordered[ncat-1] temp_Intercept;  // temporary thresholds 
##   vector&lt;lower=0&gt;[M_1] sd_1;  // group-level standard deviations
##   matrix[M_1, N_1] z_1;  // unscaled group-level effects
##   // cholesky factor of correlation matrix
##   cholesky_factor_corr[M_1] L_1;
##   vector&lt;lower=0&gt;[M_2] sd_2;  // group-level standard deviations
##   matrix[M_2, N_2] z_2;  // unscaled group-level effects
##   // cholesky factor of correlation matrix
##   cholesky_factor_corr[M_2] L_2;
## } 
## transformed parameters { 
##   // group-level effects 
##   matrix[N_1, M_1] r_1 = (diag_pre_multiply(sd_1, L_1) * z_1)&#39;;
##   vector[N_1] r_1_1 = r_1[, 1];
##   vector[N_1] r_1_2 = r_1[, 2];
##   // group-level effects 
##   matrix[N_2, M_2] r_2 = (diag_pre_multiply(sd_2, L_2) * z_2)&#39;;
##   vector[N_2] r_2_1 = r_2[, 1];
##   vector[N_2] r_2_2 = r_2[, 2];
## } 
## model { 
##   vector[N] mu = Xc * b;
##   for (n in 1:N) { 
##     mu[n] += r_1_1[J_1[n]] * Z_1_1[n] + r_1_2[J_1[n]] * Z_1_2[n] + r_2_1[J_2[n]] * Z_2_1[n] + r_2_2[J_2[n]] * Z_2_2[n];
##   } 
##   // priors including all constants 
##   target += normal_lpdf(b | 0,0.5); 
##   target += normal_lpdf(temp_Intercept | 0,3); 
##   target += normal_lpdf(sd_1 | 0,1)
##     - 2 * normal_lccdf(0 | 0,1); 
##   target += normal_lpdf(to_vector(z_1) | 0, 1);
##   target += lkj_corr_cholesky_lpdf(L_1 | 3); 
##   target += normal_lpdf(sd_2 | 0,1)
##     - 2 * normal_lccdf(0 | 0,1); 
##   target += normal_lpdf(to_vector(z_2) | 0, 1);
##   target += lkj_corr_cholesky_lpdf(L_2 | 3); 
##   // likelihood including all constants 
##   if (!prior_only) { 
##     for (n in 1:N) {
##       target += cumulative_probit_lpmf(Y[n] | mu[n], temp_Intercept, disc);
##     }
##   } 
## } 
## generated quantities { 
##   // compute actual thresholds 
##   vector[ncat - 1] b_Intercept = temp_Intercept + dot_product(means_X, b); 
##   corr_matrix[M_1] Cor_1 = multiply_lower_tri_self_transpose(L_1);
##   vector&lt;lower=-1,upper=1&gt;[NC_1] cor_1;
##   corr_matrix[M_2] Cor_2 = multiply_lower_tri_self_transpose(L_2);
##   vector&lt;lower=-1,upper=1&gt;[NC_2] cor_2;
##   // take only relevant parts of correlation matrix
##   cor_1[1] = Cor_1[1,2]; 
##   // take only relevant parts of correlation matrix
##   cor_2[1] = Cor_2[1,2]; 
## }</code></pre>
<pre class="r"><code># parameters { 
#   vector[Kc] b;  // population-level effects 
#   ordered[ncat-1] temp_Intercept;  // temporary thresholds 
#   vector&lt;lower=0&gt;[M_1] sd_1;  // group-level standard deviations
#   matrix[M_1, N_1] z_1;  // unscaled group-level effects
#   // cholesky factor of correlation matrix
#   cholesky_factor_corr[M_1] L_1;</code></pre>
<pre class="r"><code>tmp_dat &lt;- make_standata(ff,
                            data = dat_fit, 
                         prior = pp)
str(tmp_dat, 1, give.attr = FALSE)</code></pre>
<pre><code>## List of 19
##  $ N         : int 725
##  $ Y         : int [1:725(1d)] 7 6 6 7 7 5 4 6 7 6 ...
##  $ ncat      : int 7
##  $ K         : int 2
##  $ X         : num [1:725, 1:2] 1 1 1 1 1 1 1 1 1 1 ...
##  $ Z_1_1     : num [1:725(1d)] 1 1 1 1 1 1 1 1 1 1 ...
##  $ Z_1_2     : num [1:725(1d)] 0 1 0 0 1 1 0 0 0 1 ...
##  $ Z_2_1     : num [1:725(1d)] 1 1 1 1 1 1 1 1 1 1 ...
##  $ Z_2_2     : num [1:725(1d)] 0 1 0 0 1 1 0 0 0 1 ...
##  $ disc      : num 1
##  $ J_1       : int [1:725(1d)] 3 3 3 3 3 3 3 3 3 3 ...
##  $ N_1       : int 3
##  $ M_1       : int 2
##  $ NC_1      : num 1
##  $ J_2       : int [1:725(1d)] 1 2 3 4 5 6 7 8 9 10 ...
##  $ N_2       : int 242
##  $ M_2       : int 2
##  $ NC_2      : num 1
##  $ prior_only: int 0</code></pre>
<pre class="r"><code>initfun &lt;- function() {
  list(
    b = array(rnorm(tmp_dat$K, 0, 0.1), dim = length(tmp_dat$K)),
    temp_Intercept = seq(-2,2,length.out = tmp_dat$ncat-1) + rnorm(tmp_dat$ncat-1,0,0.1),
    sd_1 = runif(tmp_dat$M_1, 0.5, 1),
    z_1 = matrix(rnorm(tmp_dat$M_1*tmp_dat$N_1, 0, 0.01),
                 tmp_dat$M_1, tmp_dat$N_1),
    L_1 = diag(tmp_dat$M_1)
  )
}</code></pre>
<pre class="r"><code>#example of output
initfun()</code></pre>
<pre><code>## $b
## [1] 0.015
## 
## $temp_Intercept
## [1] -2.02 -1.17 -0.41  0.62  1.12  1.90
## 
## $sd_1
## [1] 0.65 0.57
## 
## $z_1
##        [,1]    [,2]    [,3]
## [1,]  0.003 -0.0099  0.0063
## [2,] -0.021 -0.0064 -0.0061
## 
## $L_1
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
